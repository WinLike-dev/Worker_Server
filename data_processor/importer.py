# data_processor/importer.py

from typing import List
import pandas as pd
from textblob import TextBlob
from .db_connector import get_mongodb_client
from .constants import (
    WORKER_NAME, WORKER_FILE_PATH,
    DB_NAME, RECORD_NOUNS_COLLECTION, EXCLUDE_NOUNS,
    # DB_FIELD_MAPPING ì œê±°
    DB_FIELD_DEFAULTS,
    # ğŸŒŸ DB í•„ë“œëª… ì„í¬íŠ¸
    DB_FIELD_HEADING, DB_FIELD_DATE, DB_FIELD_TAGS, DB_FIELD_ARTICLES,
    DB_FIELD_NOUNS, DB_FIELD_RECORD_ID,
    # ğŸŒŸ CSV í•„ë“œëª… ì„í¬íŠ¸ (ì¶”ê°€)
    CSV_FIELD_HEADING, CSV_FIELD_DATE, CSV_FIELD_TAGS, CSV_FIELD_ARTICLES,
    CSV_FIELD_RECORD_ID
)
import warnings
import sys

warnings.filterwarnings('ignore')


# ----------------------------------------------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# ----------------------------------------------------------------------

def extract_and_filter_proper_nouns(text) -> List[str]:
    """TextBlobì„ ì‚¬ìš©í•˜ì—¬ ê³ ìœ  ëª…ì‚¬ë¥¼ ì¶”ì¶œí•˜ê³ , ì œì™¸ ëª©ë¡ì— ìˆëŠ” ë‹¨ì–´ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤."""
    if pd.isna(text) or text is None:
        return []

    text = str(text).replace('\n', ' ')

    try:
        blob = TextBlob(text)
        # NNP/NNPS íƒœê·¸ëœ ë‹¨ì–´ ì¤‘ ì œì™¸ ëª©ë¡ì„ ê±°ë¥´ê³ , ê¸¸ì´ 1 ë˜ëŠ” ìˆ«ìì¸ ë‹¨ì–´ë¥¼ ì œê±°
        filtered_nouns = [
            word.lower()
            for word, tag in blob.tags
            if tag in ('NNP', 'NNPS') and
               word.lower() not in EXCLUDE_NOUNS and
               len(word) > 1 and not word.isdigit()
        ]

        return filtered_nouns
    except Exception as e:
        print(f"ERROR: TextBlob ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


def parse_tags(tags_str: str) -> List[str]:
    """ë¬¸ìì—´ í˜•íƒœì˜ íƒœê·¸ ëª©ë¡ì„ íŒŒì‹±í•˜ì—¬ ì†Œë¬¸ì ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not tags_str:
        return DB_FIELD_DEFAULTS.get(DB_FIELD_TAGS, [])

    tags_str = tags_str.strip().strip('[]').replace("'", "")
    if not tags_str:
        return DB_FIELD_DEFAULTS.get(DB_FIELD_TAGS, [])

    return [tag.strip().lower() for tag in tags_str.split(',') if tag.strip()]


# ----------------------------------------------------------------------
# MongoDB ì—°ê²° ë° ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
# ----------------------------------------------------------------------

def process_worker_files() -> bool:
    """
    ì›Œì»¤ì—ê²Œ í• ë‹¹ëœ CSV íŒŒì¼ ëª©ë¡ì„ ì½ì–´ ê° ë ˆì½”ë“œì˜ ëª…ì‚¬ë¥¼ ì¶”ì¶œí•˜ê³  MongoDBì— ì €ì¥í•©ë‹ˆë‹¤.
    ì‘ì—… ì„±ê³µ ì—¬ë¶€(bool)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if WORKER_NAME == 'Master' or not WORKER_FILE_PATH:
        print(f"[{WORKER_NAME}] ì›Œì»¤ ì‘ì—… ì‹¤í–‰: íŒŒì¼ì„ ì²˜ë¦¬í•˜ì§€ ì•Šê³  ê±´ë„ˆëœë‹ˆë‹¤.")
        return True

    print(f"[{WORKER_NAME}] ì›Œì»¤ ì‘ì—… ì‹œì‘. í• ë‹¹ íŒŒì¼ ëª©ë¡: {WORKER_FILE_PATH}")

    client = get_mongodb_client()
    if client is None:
        return False

    success = False

    try:
        # --- 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ---
        all_dataframes = []
        for file_path in WORKER_FILE_PATH:
            print(f"ğŸ”„ íŒŒì¼ ë¡œë“œ ì¤‘: {file_path}")
            df_chunk = pd.read_csv(file_path, encoding='utf-8')
            all_dataframes.append(df_chunk)

        df = pd.concat(all_dataframes, ignore_index=True)
        print(f"âœ… ì´ {len(all_dataframes)}ê°œ íŒŒì¼ ë¡œë“œ ì™„ë£Œ. ì „ì²´ ë ˆì½”ë“œ: {len(df)}")

        # ğŸŒŸ df.rename(columns=DB_FIELD_MAPPING) ë¡œì§ ì œê±° ğŸŒŸ
        # CSV_FIELD_... ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ ì»¬ëŸ¼ì— ì ‘ê·¼í•©ë‹ˆë‹¤.

        # í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì‚¬
        required_csv_cols = [CSV_FIELD_HEADING, CSV_FIELD_ARTICLES, CSV_FIELD_DATE, CSV_FIELD_TAGS]
        if not all(col in df.columns for col in required_csv_cols):
            missing = [col for col in required_csv_cols if col not in df.columns]
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}. CSV íŒŒì¼ í—¤ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

        # ë°ì´í„° ì •ë¦¬ ë° íƒ€ì… ë³€í™˜ (CSV_FIELD_... ì‚¬ìš©)
        df[CSV_FIELD_DATE] = pd.to_datetime(df[CSV_FIELD_DATE], errors='coerce').dt.strftime('%Y-%m-%d')
        df[CSV_FIELD_ARTICLES] = df[CSV_FIELD_ARTICLES].fillna('')
        df[CSV_FIELD_HEADING] = df[CSV_FIELD_HEADING].fillna('')
        df[CSV_FIELD_TAGS] = df[CSV_FIELD_TAGS].fillna('')

        # --- 2. ëª…ì‚¬ ì¶”ì¶œ ë° DB ì‚½ì… ---
        db = client[DB_NAME]
        record_collection = db[RECORD_NOUNS_COLLECTION]

        documents_to_insert = []
        total_records = len(df)

        print("--- ë ˆì½”ë“œë³„ ëª…ì‚¬ ì¶”ì¶œ ë° MongoDB ì§ì ‘ ì €ì¥ ì‹œì‘ (file_noun_records) ---")

        for index, row in df.iterrows():
            try:
                # í…ìŠ¤íŠ¸ ì ‘ê·¼: CSV_FIELD_... ë³€ìˆ˜ ì‚¬ìš©
                combined_text = str(row[CSV_FIELD_HEADING]) + ' ' + str(row[CSV_FIELD_ARTICLES])

                nouns = extract_and_filter_proper_nouns(combined_text)
                parsed_tags = parse_tags(str(row[CSV_FIELD_TAGS]))

                # RecordID ì²˜ë¦¬: CSV ì»¬ëŸ¼ì´ DataFrameì— ì—†ìœ¼ë©´, row.get()ì€ indexë¥¼ ë°˜í™˜í•˜ì—¬ KeyError ë°©ì§€
                record_id_value = int(row.get(CSV_FIELD_RECORD_ID, index))

                document = {
                    # DB í•„ë“œëª…(Key)ì— CSV í•„ë“œ ê°’(Value)ì„ í• ë‹¹í•©ë‹ˆë‹¤.
                    DB_FIELD_RECORD_ID: record_id_value,

                    DB_FIELD_HEADING: str(row[CSV_FIELD_HEADING]),
                    DB_FIELD_DATE: str(row[CSV_FIELD_DATE]),
                    DB_FIELD_TAGS: parsed_tags,
                    DB_FIELD_ARTICLES: str(row[CSV_FIELD_ARTICLES]),
                    DB_FIELD_NOUNS: nouns,
                    "noun_count": len(nouns)
                }
                documents_to_insert.append(document)

            except KeyError as e:
                # í•„ìˆ˜ CSV ì»¬ëŸ¼ì´ ëˆ„ë½ëœ ê²½ìš° (e.g. 'title'ì´ë‚˜ 'text'ê°€ ì—†ëŠ” ê²½ìš°)
                print(f"ERROR: ë°ì´í„° ì²˜ë¦¬ ì¤‘ í•„ìˆ˜ CSV ì»¬ëŸ¼ ëˆ„ë½ ì˜¤ë¥˜: {e}. í•´ë‹¹ ë ˆì½”ë“œ(Index {index})ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.", file=sys.stderr)
                continue
            except Exception as e:
                print(f"ERROR: ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ (Index {index}): {e}", file=sys.stderr)
                continue

            if (index + 1) % 1000 == 0:
                print(f"ì²˜ë¦¬ ì§„í–‰ ì¤‘: {index + 1}/{total_records} ë ˆì½”ë“œ")

        if documents_to_insert:
            record_collection.insert_many(documents_to_insert)
            print(f"âœ… ì´ {len(documents_to_insert)}ê°œ ë ˆì½”ë“œë¥¼ '{RECORD_NOUNS_COLLECTION}'ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸ ê²½ê³ : ì €ì¥í•  ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

        success = True

    except Exception as e:
        print(f"ERROR: ì›Œì»¤ ë°ì´í„° ì²˜ë¦¬ ë° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", file=sys.stderr)
        success = False

    finally:
        if client:
            client.close()
            print(f"[{WORKER_NAME}] Importer ì‘ì—… ì™„ë£Œ í›„ ë…ë¦½ ì—°ê²° í•´ì œ.")

    return success